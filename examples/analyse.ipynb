{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  behapy analysis pipeline\n",
    "\n",
    "This notebook walks through a basic behapy analysis pipeline using demo data that has been preprocessed with tdt2bids. We perform a linear regression to identify fluoresence signal response to various event types. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from behapy.utils import load_preprocessed_experiment\n",
    "from behapy.events import build_design_matrix, regress, find_events\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "sns.set_theme()\n",
    "\n",
    "logging.basicConfig(format='%(levelname)s:%(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load example data\n",
    "\n",
    "This pipeline is designed to be dropped into your experiment folder with structure:\n",
    "```\n",
    "└── bids_root/\n",
    "    ├── derivatives\n",
    "    ├── etc\n",
    "    ├── rawdata\n",
    "    ├── scripts/\n",
    "    │   └── analyse.py\n",
    "    └── sourcedata\n",
    "```\n",
    "\n",
    "It will also run in-place as-is with demo data from Github."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "BIDSROOT = Path('..')\n",
    "pre = load_preprocessed_experiment(BIDSROOT)\n",
    "dff_id = ['subject', 'session', 'task', 'run', 'label']\n",
    "dff_recordings = pre.recordings.loc[:, dff_id].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# z-score the dff\n",
    "dff = pre.dff.copy()\n",
    "dff['dff'] = dff.dff.groupby(dff_id, group_keys=False).apply(lambda df: (df - df.mean()) / df.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Map IPSI and CONTRA\n",
    "def _map_ipsi_contra(row):\n",
    "    r = row.iloc[0]\n",
    "    if r.label == 'RDMS':\n",
    "        events = pre.events.loc[(r.subject, r.session, r.task, r.run, r.label)].replace({'rlp': 'ipsilp', 'llp': 'contralp'})\n",
    "    elif r.label == 'LDMS':\n",
    "        events = pre.events.loc[(r.subject, r.session, r.task, r.run, r.label)].replace({'rlp': 'contralp', 'llp': 'ipsilp'})\n",
    "    else:\n",
    "        raise ValueError(f'Unknown label {r.label}')\n",
    "    return events.sort_index(level='onset')\n",
    "\n",
    "\n",
    "events = dff_recordings.groupby(dff_id).apply(_map_ipsi_contra)\n",
    "events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Map events to individual recordings\n",
    "def _get_nonevent(events, sub_events):\n",
    "    nonevent = events.loc[:, ['duration']].merge(sub_events.loc[:, ['latency']], how='left', left_index=True, right_index=True, indicator=True)\n",
    "    return nonevent.loc[nonevent._merge == 'left_only', ['duration', 'latency']]\n",
    "\n",
    "\n",
    "REWmag = find_events(events, 'mag', ['pel', 'suc'])\n",
    "NOREWmag = _get_nonevent(events.loc[events.event_id == 'mag', :], REWmag)\n",
    "first_ipsilp = find_events(events, 'ipsilp', ['ipsilp', 'contralp', 'mag'], allow_exact_matches=False)\n",
    "first_ipsilp = first_ipsilp.loc[first_ipsilp.latency < pd.to_timedelta('2s')]\n",
    "# first_ipsilp = first_ipsilp.loc[first_ipsilp.latency < 2]\n",
    "notfirst_ipsilp = _get_nonevent(events.loc[events.event_id == 'ipsilp', :], first_ipsilp)\n",
    "first_contralp = find_events(events, 'contralp', ['ipsilp', 'contralp', 'mag'], allow_exact_matches=False)\n",
    "first_contralp = first_contralp.loc[first_contralp.latency < pd.to_timedelta('2s')]\n",
    "# first_contralp = first_contralp.loc[first_contralp.latency < 2]\n",
    "notfirst_contralp = _get_nonevent(events.loc[events.event_id == 'contralp', :], first_contralp)\n",
    "new_events = pd.concat([REWmag, NOREWmag, first_ipsilp, notfirst_ipsilp, first_contralp, notfirst_contralp],\n",
    "                       keys=['REWmag', 'NOREWmag', 'first_ipsilp', 'notfirst_ipsilp', 'first_contralp', 'notfirst_contralp'],\n",
    "                       names=['event_id'])\n",
    "new_events = new_events.reset_index('event_id').loc[:, ['duration', 'event_id']]\n",
    "events = pd.concat([events, new_events]).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "plot_meta = {'Magazine': ['REWmag', 'NOREWmag']}\n",
    "# plot_meta = {'Magazine': ['REWmag', 'NOREWmag'],\n",
    "#              'Reward': ['pel', 'suc'],\n",
    "#              'First press': ['first_ipsilp', 'first_contralp'],\n",
    "#              'Other press': ['notfirst_ipsilp', 'notfirst_contralp']}\n",
    "event_ids_of_interest = sum(plot_meta.values(), [])\n",
    "events_of_interest = events.loc[events.event_id.isin(event_ids_of_interest), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "def _build_design_matrix(row):\n",
    "    r = row.iloc[0]\n",
    "    return build_design_matrix(\n",
    "        dff.loc[(r.subject, r.session, r.task, r.run, r.label), :],\n",
    "        events_of_interest.loc[(r.subject, r.session, r.task, r.run, r.label), :],\n",
    "        (-1, 2))\n",
    "design_matrix = dff_recordings.groupby(dff_id).apply(_build_design_matrix).fillna(False).astype(bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dm_filt filters on dff task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "idx = pd.IndexSlice\n",
    "dm_filt = design_matrix.loc[idx[:, :, ['FI15', 'RR5', 'RR10'], :, :, :], :].sort_index()\n",
    "\n",
    "\n",
    "def _regress(df):\n",
    "    return regress(df, dff.loc[df.index, 'dff'], min_events=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "r1 = dm_filt.loc[:, idx[sum(plot_meta.values(), []), :]].groupby(level=('subject', 'task'), group_keys=True).apply(_regress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# s1 = r1.stack(0).stack()\n",
    "s1 = r1.copy()\n",
    "s1.name = 'beta'\n",
    "s1 = s1.reset_index()\n",
    "s1['event_type'] = s1.event.map({v: k for k, l in plot_meta.items() for v in l})\n",
    "sns.relplot(data=s1, x='offset', y='beta', hue='event', row='event_type',\n",
    "            col='task',\n",
    "            kind='line', hue_order=sum(plot_meta.values(), []), aspect=2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "behapy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
